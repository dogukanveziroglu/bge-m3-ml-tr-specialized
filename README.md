# bge-m3-ml-tr-specialized

`bge-m3-ml-tr-specialized`, TÃ¼rkÃ§e bilimsel ve teknik metinler iÃ§in optimize edilmiÅŸ bir Sentence Transformer modelidir. Model, `BAAI/bge-m3` temel alÄ±narak eÄŸitilmiÅŸ olup, cÃ¼mle benzerliÄŸi, semantik arama, kavramsal eÅŸleÅŸme ve anlam odaklÄ± sÄ±nÄ±flandÄ±rma gibi gÃ¶revlerde kullanÄ±lmak Ã¼zere tasarlanmÄ±ÅŸtÄ±r.

## ğŸ§  Model Ã–zellikleri

- **Model TÃ¼rÃ¼:** Sentence Transformer  
- **Taban Model:** [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3)  
- **Uygulama AlanlarÄ±:**
  - CÃ¼mle dÃ¼zeyinde benzerlik hesaplama
  - Semantik bilgiye dayalÄ± metin eÅŸleÅŸtirme
  - Bilgi eriÅŸimi ve semantik arama sistemleri
  - Bilimsel metinlerin anlamsal kÃ¼meleme ve sÄ±ralanmasÄ±
- **Dil:** TÃ¼rkÃ§e (Ã¶zellikle teknik ve bilimsel cÃ¼mleler)
- **Maksimum Girdi UzunluÄŸu:** 8192 token  
- **Ã‡Ä±ktÄ± VektÃ¶r Boyutu:** 1024  
- **Havuzlama YÃ¶ntemi:** CLS token Ã¼zerinden  
- **Benzerlik Ã–lÃ§Ã¼tÃ¼:** KosinÃ¼s BenzerliÄŸi (Cosine Similarity)

## ğŸ” Model Mimarisi

\`\`\`python
SentenceTransformer(
  (0): Transformer({'max_seq_length': 8192, 'architecture': 'XLMRobertaModel'})
  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True})
  (2): Normalize()
)
\`\`\`

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

\`\`\`bash
pip install -U sentence-transformers
\`\`\`

\`\`\`python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("dogukanvzr/bge-m3-ml-tr-specialized")

sentences = [
    "DoÄŸruluk, bir modelin gerÃ§ek deÄŸerlere ne kadar yakÄ±n sonuÃ§lar verdiÄŸini gÃ¶sterir.",
    "Model doÄŸruluÄŸu, tahminlerin gerÃ§ek etiketlerle Ã¶rtÃ¼ÅŸme derecesini yansÄ±tÄ±r.",
    "Ã–zellik mÃ¼hendisliÄŸi, makine Ã¶ÄŸrenmesi sÃ¼reÃ§lerinde Ã¶nemli rol oynar."
]

embeddings = model.encode(sentences)

from sklearn.metrics.pairwise import cosine_similarity
scores = cosine_similarity([embeddings[0]], embeddings[1:])
print(scores)
\`\`\`

## ğŸ§ª EÄŸitim Bilgileri

- **Veri KÃ¼mesi:** [`ml-paraphrase-tr`](https://huggingface.co/datasets/dogukanvzr/ml-paraphrase-tr)
- **Boyut:** 60.000 Ã¶rnek  
- **YapÄ±:** `sentence_0`, `sentence_1`, `label` (float, 0.0â€“1.0 arasÄ± benzerlik)  
- **KayÄ±p Fonksiyonu:** `CosineSimilarityLoss` (iÃ§sel olarak `MSELoss` kullanÄ±lmÄ±ÅŸtÄ±r)  
- **EÄŸitim Epoch SayÄ±sÄ±:** 3  
- **Batch Size:** 64  

### ğŸ“ˆ EÄŸitim SÃ¼reci

| Epoch | AdÄ±m | Ortalama KayÄ±p (Loss) |
|-------|------|------------------------|
| 0.5   | 500  | 0.0338                 |
| 1.0   | 1000 | 0.0188                 |
| 1.5   | 1500 | 0.0147                 |
| 2.0   | 2000 | 0.0127                 |
| 2.5   | 2500 | 0.0105                 |

## ğŸ“Š KullanÄ±m AlanlarÄ±

Bu model, Ã¶zellikle aÅŸaÄŸÄ±daki teknik/NLP gÃ¶revleri iÃ§in uygundur:

- TÃ¼rkÃ§e teknik dÃ¶kÃ¼manlarda **anlamsal eÅŸleÅŸtirme**
- Akademik ve bilimsel metinlerde **benzerlik analizi**
- **Embedding tabanlÄ± bilgi eriÅŸim sistemleri**
- **Paraphrase detection** (anlamca yakÄ±n cÃ¼mle Ã§iftlerinin tespiti)
- **Semantic Clustering** (anlam temelli kÃ¼meleme)
- Soru-cevap sistemlerinde **intent eÅŸleÅŸtirme**

## ğŸ’¡ Ã–rnek DeÄŸerlendirme

\`\`\`python
s1 = "Makine Ã¶ÄŸrenmesi algoritmalarÄ±, geÃ§miÅŸ verilerden Ã¶ÄŸrenerek geleceÄŸi tahmin eder."
s2 = "Model, Ã¶ÄŸrenilmiÅŸ Ã¶rÃ¼ntÃ¼lerden faydalanarak tahmin yÃ¼rÃ¼tÃ¼r."
s3 = "Veri seti boyutu, modelin genelleme kapasitesini etkileyebilir."

embs = model.encode([s1, s2, s3])
from sklearn.metrics.pairwise import cosine_similarity
sim = cosine_similarity([embs[0]], embs[1:])
print(sim)
\`\`\`

## âš™ï¸ GeliÅŸtirme OrtamÄ±

- Python: 3.12.7  
- Sentence Transformers: 5.0.0  
- Transformers: 4.56.0.dev0  
- PyTorch: 2.7.1+cu128  
- Accelerate: 1.9.0  
- Datasets: 4.0.0  
- Tokenizers: 0.21.4  

## ğŸ“š AtÄ±f

\`\`\`bibtex
@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}
\`\`\`

## âš ï¸ SÄ±nÄ±rlÄ±lÄ±klar

- Model, teknik ve bilimsel dil Ã¼zerinde eÄŸitildiÄŸi iÃ§in gÃ¼nlÃ¼k konuÅŸma dili veya mecaz iÃ§eren ifadelerde dÃ¼ÅŸÃ¼k performans gÃ¶sterebilir.
- KÃ¼ltÃ¼rel baÄŸlam, ironi, deyimsel ifadeler gibi alanlarda genelleme yeteneÄŸi sÄ±nÄ±rlÄ±dÄ±r.
- EÄŸitim verisinde bias oluÅŸmamÄ±ÅŸ olsa da, Ã§Ä±ktÄ±lar dikkatle deÄŸerlendirilmelidir.

## ğŸ“¬ Ä°letiÅŸim ve Geri Bildirim

Model ile ilgili sorun bildirmek, Ã¶neride bulunmak ya da katkÄ±da bulunmak iÃ§in:

- ğŸ“§ Hugging Face Profili: [@dogukanvzr](https://huggingface.co/dogukanvzr)
- ğŸ“‚ Veri kÃ¼mesi: [`ml-paraphrase-tr`](https://huggingface.co/datasets/dogukanvzr/ml-paraphrase-tr)